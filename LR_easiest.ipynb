{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import inf\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn import  preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import xgboost as xgb\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "USE_PARTIAL_DATA = 0\n",
    "SEED = 12\n",
    "BLOCK_SIZE = 10\n",
    "\n",
    "USE_ORIGINAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_wave(filename):\n",
    "    print \"loading data...\"\n",
    "\n",
    "    data = spio.loadmat(filename, squeeze_me=True)\n",
    "\n",
    "    print \"data loaded\"\n",
    "\n",
    "    #I_AC_ALL contains reflection information matrix and the freqs that were measures\n",
    "    matrix = data['I_AC_ALL']\n",
    "    freq = data['sfx']\n",
    "    print freq\n",
    "\n",
    "    matrix = np.asarray(matrix)\n",
    "\n",
    "    #matrix indices are (x,y,color,freq)\n",
    "\n",
    "    #Work with just the first color for now\n",
    "    wave = matrix[:,:,0,:]\n",
    "\n",
    "    #plot an example image at just one frequency\n",
    "    image = wave[:,:,4]\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "    return wave, freq\n",
    "\n",
    "\n",
    "cancer_wave, freq = extract_wave('data/I_AC_ALL0a.mat')\n",
    "control_wave, freq = extract_wave('data/I_AC_ALL0b.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_infs(x):\n",
    "    x[x == -inf] = 0\n",
    "    x[x == inf] = 0\n",
    "    x[np.isnan(x)] = 0\n",
    "    return x\n",
    "    \n",
    "\n",
    "\n",
    "#Extract sections with cancer and sections without cancer\n",
    "cancer = cancer_wave[350:550, 500:700, :]\n",
    "cancer = remove_infs(cancer)\n",
    "\n",
    "not_cancer = control_wave[200:900, 250:550, :]\n",
    "not_cancer = remove_infs(not_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cancer_wave.shape\n",
    "print cancer.shape\n",
    "cancer = cancer.reshape((cancer.shape[0] * cancer.shape[1], not_cancer.shape[2]))\n",
    "\n",
    "not_cancer = not_cancer.reshape((not_cancer.shape[0] * not_cancer.shape[1],not_cancer.shape[2]))\n",
    "\n",
    "X = np.vstack((cancer, not_cancer))\n",
    "\n",
    "y = [1] * len(cancer) + [0] * len(not_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do some feature engineering\n",
    "\n",
    "def find_power_law(ydatas, xdata):\n",
    "    amps = np.zeros((ydatas.shape[0],1))\n",
    "    indexs = np.zeros((ydatas.shape[0],1))\n",
    "    i = 0\n",
    "    for ydata in ydatas:\n",
    "        logx = np.log10(xdata)\n",
    "        logy = np.log10(ydata)\n",
    "\n",
    "        pfinal = np.polyfit(logx,logy,1)\n",
    "\n",
    "        index = pfinal[0]\n",
    "        amp = 10.0**pfinal[1]\n",
    "\n",
    "        amps[i][0] = amp\n",
    "        indexs[i][0] = index\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    return amps, indexs\n",
    "\n",
    "amps, indexs = find_power_law(X, freq)\n",
    "\n",
    "if USE_ORIGINAL:\n",
    "    X = np.hstack((X,amps,indexs))\n",
    "else:\n",
    "    X = np.hstack((amps,indexs))\n",
    "\n",
    "X = remove_infs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit models and make predictions.\n",
    "We'll use one-hot encoding to transform our categorical features\n",
    "into binary features.\n",
    "y and X will be numpy array objects.\n",
    "\"\"\"\n",
    "\n",
    "def bagged_set(X_t,y_c,model, myseed, estimators, xt, update_seed=True):\n",
    "    \n",
    "    # create array object to hold predictions \n",
    "    baggedpred=[ 0.0  for d in range(0, (xt.shape[0]))]\n",
    "    #loop for as many times as we want bags\n",
    "    for n in range (0, estimators):\n",
    "        #shuff;e first, aids in increasing variance and forces different results\n",
    "        #X_t,y_c=shuffle(Xs,ys, random_state=seed+n)\n",
    "\n",
    "        if update_seed: # update seed if requested, to give a slightly different model\n",
    "            model.set_params(seed=myseed + n)\n",
    "        model.fit(X_t,y_c) # fit model0.0917411475506\n",
    "        preds=model.predict_proba(xt)[:,1] # predict probabilities\n",
    "        # update bag's array\n",
    "\n",
    "        baggedpred+=preds\n",
    "    # divide with number of bags to create an average estimate            \n",
    "\n",
    "    baggedpred = np.true_divide(baggedpred,float(estimators))\n",
    "    # return probabilities            \n",
    "    return np.array(baggedpred) \n",
    "\n",
    "filename=\"LR\" # nam prefix\n",
    "#model = linear_model.LogisticRegression(C=3)  # the classifier we'll use\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "# === load data in memory === #\n",
    "print \"loading data\"\n",
    "\n",
    "\n",
    "if USE_PARTIAL_DATA == 1:\n",
    "    X, X_discard, y, y_discard = train_test_split(X, y, train_size=PERCENT_DATA, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create arrays to hold cv an dtest predictions\n",
    "train_stacker=[ 0.0  for k in range (0,(X.shape[0])) ] \n",
    "\n",
    "# === training & metrics === #\n",
    "mean_auc = 0.0\n",
    "bagging=5 # number of models trained with different seeds\n",
    "n = 5  # number of folds in strattified cv\n",
    "kfolder=StratifiedKFold(y, n_folds= n,shuffle=True, random_state=SEED)     \n",
    "i=0\n",
    "for train_index, test_index in kfolder: # for each train and test pair of indices in the kfolder object\n",
    "    # creaning and validation sets\n",
    "    X_train, X_cv = X[train_index], X[test_index]\n",
    "    y_train, y_cv = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    #print (\" train size: %d. test size: %d, cols: %d \" % ((X_train.shape[0]) ,(X_cv.shape[0]) ,(X_train.shape[1]) ))\n",
    "\n",
    "    # if you want to perform feature selection / hyperparameter\n",
    "    # optimization, this is where you want to do it\n",
    "\n",
    "    # train model and make predictions \n",
    "    preds=bagged_set(X_train,y_train,model, SEED , bagging, X_cv, update_seed=False)   \n",
    "\n",
    "\n",
    "    # compute AUC metric for this CV fold\n",
    "    roc_auc = roc_auc_score(y_cv, preds)\n",
    "    print \"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc)\n",
    "    mean_auc += roc_auc\n",
    "\n",
    "    no=0\n",
    "    for real_index in test_index:\n",
    "             train_stacker[real_index]=(preds[no])\n",
    "             no+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_cv, preds)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "mean_auc/=n\n",
    "print (\" Average AUC: %f\" % (mean_auc) )\n",
    "# print (\" printing train datasets \")\n",
    "# printfilcsve(np.array(train_stacker), filename + \".train.csv\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# === Predictions === #\n",
    "# When making predictions, retrain the model on the whole training set\n",
    "model.fit(X,y)\n",
    "\n",
    "training_error = roc_auc_score(y, model.predict_proba(X)[:,1])\n",
    "\n",
    "print training_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find the predictions\n",
    "test_matrix = remove_infs(cancer_wave)\n",
    "X_test = test_matrix.reshape((test_matrix.shape[0] * test_matrix.shape[1], test_matrix.shape[2]))\n",
    "\n",
    "#Do some feature engineering\n",
    "ydatas = X_test\n",
    "xdata = freq\n",
    "\n",
    "amps = np.zeros((ydatas.shape[0],1))\n",
    "indexs = np.zeros((ydatas.shape[0],1))\n",
    "i = 0\n",
    "for ydata in ydatas:\n",
    "    logx = np.log10(xdata)\n",
    "    logy = np.log10(ydata)\n",
    "\n",
    "    pfinal = np.polyfit(logx,logy,1)\n",
    "\n",
    "    index = pfinal[0]\n",
    "    amp = 10.0**pfinal[1]\n",
    "\n",
    "    amps[i][0] = amp\n",
    "    indexs[i][0] = index\n",
    "\n",
    "    i += 1\n",
    "\n",
    "if USE_ORIGINAL:\n",
    "    X_test = np.hstack((X_test ,amps,indexs))\n",
    "else:\n",
    "    X_test = np.hstack((amps,indexs))\n",
    "X_test = remove_infs(X_test)\n",
    "\n",
    "preds = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, m, _ = cancer_wave.shape\n",
    "\n",
    "special_features = np.hstack((amps,indexs))\n",
    "special_features = remove_infs(special_features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(special_features)\n",
    "\n",
    "new_image = kmeans.labels_.reshape((n,m))\n",
    "\n",
    "plt.imshow(new_image)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Put them in a displayable format\n",
    "\n",
    "n, m, _ = test_matrix.shape\n",
    "\n",
    "heatmap = preds.reshape((n,m))\n",
    "# heatmap = np.clip(heatmap, 0, 0.06)\n",
    "plt.imshow(heatmap)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
